{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Environment\n",
    "\n",
    "Before we begin our data collection and analysis, we need to install the necessary Python libraries. This cell installs the following packages:\n",
    "\n",
    "- `pandas`: A powerful data manipulation and analysis library\n",
    "- `ntscraper`: A tool for scraping tweets from Twitter (X)\n",
    "- `datetime`: A module for working with dates and times\n",
    "- `ftfy`: A library for fixing text encoding issues\n",
    "\n",
    "Run this cell to install these dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OkMxIZa0yz-V",
    "outputId": "2247d98f-855c-4289-8a64-9b7fbf49afcc"
   },
   "outputs": [],
   "source": [
    "!pip install pandas ntscraper datetime ftfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "In this section, we import the necessary libraries for our Political Sentiment Analyzer project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16jlwxRBzUo5"
   },
   "outputs": [],
   "source": [
    "from ntscraper import Nitter\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import pandas as pd\n",
    "from ftfy import fix_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `correct_encoding` Function\n",
    "\n",
    "The `correct_encoding` function ensures that the text from tweets is properly encoded, fixing any issues that may arise from encoding errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_encoding(text):\n",
    "    return fix_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `format_date` Function\n",
    "\n",
    "The `format_date` function cleans and formats the date string from the tweet data into a standardized format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(date_str):\n",
    "    cleaned_date_str = date_str.replace('Â', '').replace('·', '').strip()\n",
    "    date_obj = datetime.strptime(cleaned_date_str, '%b %d, %Y %I:%M %p UTC')\n",
    "    return date_obj.strftime('%Y-%m-%d %I:%M %p UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `extract_tweet_id` Function\n",
    "\n",
    "The `extract_tweet_id` function extracts the unique tweet ID from the tweet's URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRZAn0cZBM96"
   },
   "outputs": [],
   "source": [
    "def extract_tweet_id(url):\n",
    "    match = re.search(r'/status/(\\d+)', url)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `get_info` Function\n",
    "\n",
    "The `get_info` function extracts and processes essential information from each tweet. This function returns a dictionary containing the tweet's ID, formatted date, and corrected text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iemALEUk5bGq"
   },
   "outputs": [],
   "source": [
    "def get_info(tweet):\n",
    "    return {\n",
    "        'id': extract_tweet_id(tweet['link']),\n",
    "        'date': format_date(tweet['date']),\n",
    "        'text': correct_encoding(tweet['text'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `get_tweets` Function\n",
    "\n",
    "The following function `get_tweets` is designed to scrape tweets based on specific search terms within a defined date range. It uses the `Nitter` module from the `ntscraper` library to fetch tweets and then processes them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkP8scT4zn3K"
   },
   "outputs": [],
   "source": [
    "def get_tweets(terms, start_date_str, end_date_str=None):\n",
    "    end_date = datetime.strptime(end_date_str, '%Y-%m-%d') if end_date_str else datetime.now()\n",
    "    curr_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
    "\n",
    "    while curr_date <= end_date:\n",
    "        next_date = curr_date + timedelta(days=1)\n",
    "\n",
    "        curr_date_str = curr_date.strftime('%Y-%m-%d')\n",
    "        next_date_str = next_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        scraper = Nitter(log_level=1, skip_instance_check=False)\n",
    "\n",
    "        for term in terms:\n",
    "            try:\n",
    "                response = scraper.get_tweets(term, since=curr_date_str, until=next_date_str, near='India', language='en')\n",
    "\n",
    "                new_tweets = []\n",
    "\n",
    "                for tweet in response.get('tweets', []):\n",
    "                    new_tweets.append(get_info(tweet))\n",
    "\n",
    "                if new_tweets:\n",
    "                    yield new_tweets\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        print(f'Tweets for {curr_date} collected!')\n",
    "\n",
    "        curr_date = next_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Search Terms\n",
    "\n",
    "Below is a list of search terms that will be used to collect tweets related to the India budget. These terms encompass various aspects of the budget, including economic policies, sectors, and public reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZuAnnX8DFx5"
   },
   "outputs": [],
   "source": [
    "terms = [\n",
    "    'Budget',\n",
    "    'India Budget',\n",
    "    'Union Budget',\n",
    "    'Indian Economy',\n",
    "    'Finance Minister Budget',\n",
    "    'Economic Survey',\n",
    "    'Tax Reforms',\n",
    "    'Income Tax',\n",
    "    'GST',\n",
    "    'Fiscal Deficit',\n",
    "    'Subsidies',\n",
    "    'Infrastructure Spending',\n",
    "    'Public Expenditure',\n",
    "    'Social Welfare Budget',\n",
    "    'Agriculture Budget',\n",
    "    'Healthcare Budget',\n",
    "    'Modi Government Budget',\n",
    "    'FM Nirmala Sitharaman Budget',\n",
    "    'Indian Parliament Budget',\n",
    "    'Budget Reactions',\n",
    "    'Opposition Response Budget',\n",
    "    'Middle Class Budget',\n",
    "    'Corporate Tax Budget',\n",
    "    'Defense Budget',\n",
    "    'Railway Budget',\n",
    "    'Education Budget',\n",
    "    'Automobile Budget',\n",
    "    'Real Estate Budget',\n",
    "    'Startups Budget',\n",
    "    'MSME Budget',\n",
    "    'Banking Sector Budget',\n",
    "    'Energy Sector Budget',\n",
    "    'Technology Budget',\n",
    "    'Digital India Budget',\n",
    "    'Green Energy Budget',\n",
    "    'Rural Development Budget',\n",
    "    'Budget Session',\n",
    "    'Budget Day',\n",
    "    'Budget Announcement',\n",
    "    'Pre-Budget Survey',\n",
    "    'Post-Budget Analysis'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the `generate_date_ranges` Function\n",
    "\n",
    "The `generate_date_ranges` function creates a list of date ranges for each year within a specified period. These ranges can be used to systematically collect tweets from specific years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHPkV_v-FnmC"
   },
   "outputs": [],
   "source": [
    "def generate_date_ranges(start_year, end_year):\n",
    "    date_ranges = []\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        start_date = f'{year}-01-01'\n",
    "        end_date = f'{year + 1}-01-01'\n",
    "        date_ranges.append((start_date, end_date))\n",
    "\n",
    "    return date_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting and Storing Tweets\n",
    "\n",
    "The following code collects tweets for each year within the specified range and saves them to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lug9vDNLIGjj",
    "outputId": "0506e3a8-269c-415f-d8f0-7952400eacef",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_year = 2021\n",
    "end_year = datetime.now().year\n",
    "\n",
    "date_ranges = generate_date_ranges(start_year, end_year)\n",
    "\n",
    "for start_date_str, end_date_str in date_ranges:\n",
    "        if end_date_str > datetime.now().strftime('%Y-%m-%d'):\n",
    "            end_date_str = None\n",
    "\n",
    "        year = datetime.strptime(start_date_str, '%Y-%m-%d').year\n",
    "        file_path = f'../../data/budget_{year}.csv'\n",
    "\n",
    "        for tweets in get_tweets(terms, start_date_str, end_date_str):\n",
    "            df = pd.DataFrame(tweets)\n",
    "            df.to_csv(file_path, mode='a', index=False, header=False, encoding='utf-8')\n",
    "\n",
    "        print(f'Tweets for year {year} collected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Saving Tweet Data\n",
    "\n",
    "The following code reads tweet data from CSV files, removes duplicates, and performs data cleaning and reformatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(start_year, end_year + 1):\n",
    "    file_path = f'../../data/budget_{year}.csv'\n",
    "    \n",
    "    df = pd.read_csv(file_path, header=None, names=['tweet_id', 'datetime', 'text'])\n",
    "\n",
    "    df.drop_duplicates(subset='tweet_id', keep='first', inplace=True)\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %I:%M %p %Z')\n",
    "    \n",
    "    df.sort_values(by='datetime', inplace=True)\n",
    "    \n",
    "    df = df[['datetime', 'text']]\n",
    "    \n",
    "    df.to_csv(file_path, index=False)\n",
    "            \n",
    "    print(f'Cleaned data for year {year}, saved successfully!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
